@misc{li2024safetyanalystinterpretabletransparentsteerable,
      abbr={Preprint},
      title={SafetyAnalyst: Interpretable, transparent, and steerable LLM safety moderation}, 
      author={Jing-Jing Li and Valentina Pyatkin and Max Kleiman-Weiner and Liwei Jiang and Nouha Dziri and Anne G. E. Collins and Jana Schaich Borg and Maarten Sap and Yejin Choi and Sydney Levine},
      abstract={The ideal LLM content moderation system would be both structurally interpretable (so its decisions can be explained to users) and steerable (to reflect a community's values or align to safety standards). However, current systems fall short on both of these dimensions. To address this gap, we present SafetyAnalyst, a novel LLM safety moderation framework. Given a prompt, SafetyAnalyst creates a structured ``harm-benefit tree,'' which identifies 1) the actions that could be taken if a compliant response were provided, 2) the harmful and beneficial effects of those actions (along with their likelihood, severity, and immediacy), and 3) the stakeholders that would be impacted by those effects. It then aggregates this structured representation into a harmfulness score based on a parameterized set of safety preferences, which can be transparently aligned to particular values. Using extensive harm-benefit features generated by SOTA LLMs on 19k prompts, we fine-tuned an open-weight LM to specialize in generating harm-benefit trees through symbolic knowledge distillation. On a comprehensive set of prompt safety benchmarks, we show that our system (average F1=0.75) outperforms existing LLM safety moderation systems (average F1$<$0.72) on prompt harmfulness classification, while offering the additional advantages of interpretability and steerability.},
      year={2024},
      eprint={2410.16665},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.16665}, 
      html={https://jl3676.github.io/SafetyAnalyst},
      pdf={https://arxiv.org/pdf/2410.16665},
      selected={true}
}

@article{li2024algorithmic,
  abbr={Journal},
  title={An algorithmic account for how humans efficiently learn, transfer, and compose hierarchically structured decision policies},
  author={Li, Jing-Jing and Collins, Anne},
  abstract={Learning structures that effectively abstract decision policies is key to the flexibility of human intelligence. Previous work has shown that humans use hierarchically structured policies to efficiently navigate complex and dynamic environments. However, the computational processes that support the learning and construction of such policies remain insufficiently understood. To address this question, we tested 1,026 human participants on a decision-making task where they could learn, transfer, and recompose multiple sets of hierarchical policies. We propose a novel algorithmic account for the learning processes underlying observed human behavior. We show that humans rely on compressed policies over states in early learning, which gradually unfold into hierarchical representations via meta-learning and Bayesian inference. Our modeling evidence suggests that these hierarchical policies are structured in a temporally backward, rather than forward, fashion. Taken together, these algorithmic architectures characterize how the interplay between reinforcement learning, policy compression, meta-learning, and working memory supports structured decision-making and compositionality in a resource-rational way.},
  year={2025},
  volume={254},
  pages={105967},
  publisher={Elsevier},
  journal={Cognition},
  google_scholar_id={UeHWp8X0CEIC},
  html={https://www.sciencedirect.com/science/article/pii/S0010027724002531},
  pdf={learning_hierarchy.pdf},
  code={https://github.com/jl3676/learning_hierarchy},
  selected={true}
}

@article{li2024dynamic,
  abbr={Journal},
  title={Dynamic noise estimation: A generalized method for modeling noise fluctuations in decision-making},
  author={Li, Jing-Jing and Shi, Chengchun and Li, Lexin and Collins, Anne GE},
  abstract={Computational cognitive modeling is an important tool for understanding the processes supporting human and animal decision-making. Choice data in decision-making tasks are inherently noisy, and separating noise from signal can improve the quality of computational modeling. Common approaches to model decision noise often assume constant levels of noise or exploration throughout learning (e.g., the softmax policy). However, this assumption is not guaranteed to hold – for example, a subject might disengage and lapse into an inattentive phase for a series of trials in the middle of otherwise low-noise performance. Here, we introduce a new, computationally inexpensive method to dynamically estimate the levels of noise fluctuations in choice behavior, under a model assumption that the agent can transition between two discrete latent states (e.g., fully engaged and random). Using simulations, we show that modeling noise levels dynamically instead of statically can substantially improve model fit and parameter estimation, especially in the presence of long periods of noisy behavior, such as prolonged lapses of attention. We further demonstrate the empirical benefits of dynamic noise estimation at the individual and group levels by validating it on four published datasets featuring diverse populations, tasks, and models. Based on the theoretical and empirical evaluation of the method reported in the current work, we expect that dynamic noise estimation will improve modeling in many decision-making paradigms over the static noise estimation method currently used in the modeling literature, while keeping additional model complexity and assumptions minimal.},
  journal={Journal of Mathematical Psychology},
  volume={119},
  pages={102842},
  year={2024},
  publisher={Elsevier},
  html={https://www.sciencedirect.com/science/article/pii/S0022249624000129},
  pdf={dynamic_noise_estimation.pdf},
  code={https://github.com/jl3676/dynamic_noise_estimation},
  google_scholar_id={2osOgNQ5qMEC},
  selected={true}
}

@article{pan2024latent,
  abbr={Preprint},
  title={Latent Variable Sequence Identification for Cognitive Models with Neural Bayes Estimation},
  author={Pan, Ti-Fen and Li, Jing-Jing and Thompson, Bill and Collins, Anne},
  journal={arXiv preprint arXiv:2406.14742},
  year={2024},
  abstract={Extracting time-varying latent variables from computational cognitive models is a key step in model-based neural analysis, which aims to understand the neural correlates of cognitive processes. However, existing methods only allow researchers to infer latent variables that explain subjects’ behavior in a relatively small class of cognitive models. For example, a broad class of relevant cognitive models with analytically intractable likelihood is currently out of reach from standard techniques, based on Maximum a Posteriori parameter estimation. Here, we present an approach that extends neural Bayes estimation to learn a direct mapping between experimental data and the targeted latent variable space using recurrent neural networks and simulated datasets. We show that our approach achieves competitive performance in inferring latent variable sequences in both tractable and intractable models. Furthermore, the approach is generalizable across different computational models and is adaptable for both continuous and discrete latent spaces. We then demonstrate its applicability in real world datasets. Our work underscores that combining recurrent neural networks and simulation-based inference to identify latent variable sequences can enable researchers to access a wider class of cognitive models for model-based neural analyses, and thus test a broader set of theories.},
  pdf={https://arxiv.org/pdf/2406.14742}, 
  google_scholar_id={IjCSPb-OGe4C}
}

@article{jin2024neural,
  abbr={Preprint},
  title={Neural mechanisms of awareness of action},
  author={Jin, David S and Agdali, Oumayma and Yadav, Taruna and Kronemer, Sharif I and Kunkler, Sydney and Majumder, Shweta and Khurana, Maya and McCusker, Marie C and Fu, Ivory and Siff, Emily J and Khalaf, Aya and Christison-Lagay, Kate L and Aerts, Shanae L and Xin, Qilong and Li, Jing-Jing and McGill, Sarah H and Crowley, Michael J and Blumenfeld, Hal},
  journal={bioRxiv},
  pages={2024--08},
  year={2024},
  publisher={Cold Spring Harbor Laboratory},
  abstract={The origins of awareness of action (AoA), the ability to report an action just performed, remain elusive. Differing theories ascribe AoA to pre-action, efferent motor/volitional mechanisms versus post-action, afferent sensory/perceptual neural mechanisms. To study these two types of mechanisms and others, we developed a paradigm where very similar aware and unaware actions occur repeatedly. Aware actions demonstrated larger neurophysiological signals both preceding and following movement. The differences included well-known volitional and perceptual event related potentials (PMP, N140, P300), as well as frontal midline theta, event-related alpha/beta desynchronization, and post-move blink rates. On longer time scales, we identified a novel event related potential preceding unaware moves, and found behavioral and pupillometric evidence for decreased attention and arousal over minutes concurrent with AoA loss. Our findings suggest that both dynamic, individual action-associated volitional and perceptual neural activity, as well as long-term attention and arousal states play a role in maintaining AoA.},
  pdf={https://www.biorxiv.org/content/10.1101/2024.08.15.608153v2.full.pdf},
  google_scholar_id={Tyk-4Ss8FVUC}
}

@inproceedings{li2023generalized,
  abbr={Conference},
  title={A generalized method for dynamic noise inference in modeling sequential decision-making},
  author={Li, Jing-Jing and Shi, Chengchun and Li, Lexin and Collins, Anne GE},
  abstract={Computational cognitive modeling is an important tool for understanding the processes that support human and animal decision-making. Choice data in sequential decision-making tasks are inherently noisy, and separating noise from signal can improve the quality of computational modeling. Currently, most models assume that noise is constant, or static, typically by including a parameter (e.g., uniform ε) to estimate the noise level. However, this assumption is not guaranteed to hold -- for example, an agent can lapse into an inattentive phase for a series of trials in the middle of otherwise low-noise performance. Assuming that noise is static could bias parameter and model identification. Here, we propose a new method to dynamically infer noise in choice behavior, under a model assumption that agents can transition between two discrete latent states (for example, attentive and noisy). Using four empirical datasets with diverse behavioral and modeling features, we demonstrate that our method improves model fit and that it can be easily incorporated into existing fitting procedures, including maximum likelihood estimation and hierarchical Bayesian modeling.},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={45},
  number={45},
  year={2023},
  html={https://escholarship.org/uc/item/7p00v6c5},
  pdf={https://escholarship.org/content/qt7p00v6c5/qt7p00v6c5.pdf},
  google_scholar_id={qjMakFHDy7sC}
}

@article{mccafferty2023decreased,
  abbr={Journal},
  title={Decreased but diverse activity of cortical and thalamic neurons in consciousness-impairing rodent absence seizures},
  author={McCafferty, Cian and Gruenbaum, Benjamin F and Tung, Renee and Li, Jing-Jing and Zheng, Xinyuan and Salvino, Peter and Vincent, Peter and Kratochvil, Zachary and Ryu, Jun Hwan and Khalaf, Aya and Swift, Kohl and Akbari, Rashid and Islam, Wasif and Antwi, Prince and Johnson, Emily A and Vitkovskiy, Petr and Sampognaro, James and Freedman, Isaac G and Kundishora, Adam and Depaulis, Antoine and David, François and Crunelli, Vincenzo and Sanganahalli, Basavaraju G and Herman, Peter and Hyder, Fahmeed and Blumenfeld, Hal},
  journal={Nature Communications},
  volume={14},
  number={1},
  pages={117},
  year={2023},
  html={https://www.nature.com/articles/s41467-022-35535-4},
  google_scholar_id={9yKSN-GCB0IC},
  publisher={Nature Publishing Group UK London},
  abstract={Absence seizures are brief episodes of impaired consciousness, behavioral arrest, and unresponsiveness, with yet-unknown neuronal mechanisms. Here we report that an awake female rat model recapitulates the behavioral, electroencephalographic, and cortical functional magnetic resonance imaging characteristics of human absence seizures. Neuronally, seizures feature overall decreased but rhythmic firing of neurons in cortex and thalamus. Individual cortical and thalamic neurons express one of four distinct patterns of seizure-associated activity, one of which causes a transient initial peak in overall firing at seizure onset, and another which drives sustained decreases in overall firing. 40–60 s before seizure onset there begins a decline in low frequency electroencephalographic activity, neuronal firing, and behavior, but an increase in higher frequency electroencephalography and rhythmicity of neuronal firing. Our findings demonstrate that prolonged brain state changes precede consciousness-impairing seizures, and that during seizures distinct functional groups of cortical and thalamic neurons produce an overall transient firing increase followed by a sustained firing decrease, and increased rhythmicity.}
}

@inproceedings{li2022credit,
  abbr={Conference},
  title={Credit assignment in hierarchical option transfer},
  author={Li, Jing-Jing and Xia, Liyu and Dong, Flora and Collins, Anne GE},
  abstract={Humans have the exceptional ability to efficiently structure past knowledge during learning to enable fast generalization. Xia and Collins (2021) evaluated this ability in a hierarchically structured, sequential decision-making task, where participants could build “options” (strategy “chunks”) at multiple levels of temporal and state abstraction. A quantitative model, the Option Model, captured the transfer effects observed in human participants, suggesting that humans create and compose hierarchical options and use them to explore novel contexts. However, it is not well understood how learning in a new context is attributed to new and old options (i.e., the credit assignment problem). In a new context with new contingencies, where participants can recompose some aspects of previously learned options, do they reliably create new options or overwrite existing ones? Does the credit assignment depend on how similar the new option is to an old one? In our experiment, two groups of participants (n=124 and n=104) learned hierarchically structured options, experienced different amounts of negative transfer in a new option context, and were subsequently tested on the previously learned options. Behavioral analysis showed that old options were successfully reused without interference, and new options were appropriately created and credited. This credit assignment did not depend on how similar the new option was to the old option, showing great flexibility and precision in human hierarchical learning. These behavioral results were captured by the Option Model, providing further evidence for option learning and transfer in humans.},
  booktitle={CogSci... Annual Conference of the Cognitive Science Society. Cognitive Science Society (US). Conference},
  volume={44},
  pages={948},
  year={2022},
  organization={NIH Public Access},
  google_scholar_id={u-x6o8ySG0sC},
  html={https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9751259/},
  pdf={https://escholarship.org/content/qt6pc5s178/qt6pc5s178_noSplash_fadabee184e56ba5cded556553f1fca1.pdf?t=reckne}
}