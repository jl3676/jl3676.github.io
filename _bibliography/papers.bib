@article{li2026pluriharmsbenchmarkingspectrumhuman,
      title={PluriHarms: Benchmarking the Full Spectrum of Human Judgments on AI Harm}, 
      author={Jing-Jing Li and Joel Mire and Eve Fleisig and Valentina Pyatkin and Anne Collins and Maarten Sap and Sydney Levine},
      year={2026},
      journal={ICLR},
      pdf={https://arxiv.org/pdf/2601.08951},
      code={https://jl3676.github.io/PluriHarms/},
      selected={true},
      abstract={Current AI safety frameworks, which often treat harmfulness as binary, lack the flexibility to handle borderline cases where humans meaningfully disagree. To build more pluralistic systems, it is essential to move beyond consensus and instead understand where and why disagreements arise. We introduce PluriHarms, a benchmark designed to systematically study human harm judgments across two key dimensions -- the harm axis (benign to harmful) and the agreement axis (agreement to disagreement). Our scalable framework generates prompts that capture diverse AI harms and human values while targeting cases with high disagreement rates, validated by human data. The benchmark includes 150 prompts with 15,000 ratings from 100 human annotators, enriched with demographic and psychological traits and prompt-level features of harmful actions, effects, and values. Our analyses show that prompts that relate to imminent risks and tangible harms amplify perceived harmfulness, while annotator traits (e.g., toxicity experience, education) and their interactions with prompt content explain systematic disagreement. We benchmark AI safety models and alignment methods on PluriHarms, finding that while personalization significantly improves prediction of human harm judgments, considerable room remains for future progress. By explicitly targeting value diversity and disagreement, our work provides a principled benchmark for moving beyond "one-size-fits-all" safety toward pluralistically safe AI.},
      preview={pluriharms.jpg},
      keywords={Conference, AI Safety, LLM}
}

@misc{li2025stacinnocenttoolsform,
      title={STAC: When Innocent Tools Form Dangerous Chains to Jailbreak LLM Agents}, 
      author={Jing-Jing Li and Jianfeng He and Chao Shang and Devang Kulshreshtha and Xun Xian and Yi Zhang and Hang Su and Sandesh Swamy and Yanjun Qi},
      year={2025},
      eprint={2509.25624},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2509.25624}, 
      html={https://arxiv.org/abs/2509.25624},
      pdf={https://arxiv.org/pdf/2509.25624},
      code={https://github.com/amazon-science/MultiTurnAgentAttack},
      keywords={Preprint, AI Safety, LLM},
      preview={stac.jpg},
      selected={false},
      abstract={As LLMs advance into autonomous agents with tool-use capabilities, they introduce security challenges that extend beyond traditional content-based LLM safety concerns. This paper introduces Sequential Tool Attack Chaining (STAC), a novel multi-turn attack framework that exploits agent tool use. STAC chains together tool calls that each appear harmless in isolation but, when combined, collectively enable harmful operations that only become apparent at the final execution step. We apply our framework to automatically generate and systematically evaluate 483 STAC cases, featuring 1,352 sets of user-agent-environment interactions and spanning diverse domains, tasks, agent types, and 10 failure modes. Our evaluations show that state-of-the-art LLM agents, including GPT-4.1, are highly vulnerable to STAC, with attack success rates (ASR) exceeding 90% in most cases. The core design of STAC's automated framework is a closed-loop pipeline that synthesizes executable multi-step tool chains, validates them through in-environment execution, and reverse-engineers stealthy multi-turn prompts that reliably induce agents to execute the verified malicious sequence. We further perform defense analysis against STAC and find that existing prompt-based defenses provide limited protection. To address this gap, we propose a new reasoning-driven defense prompt that achieves far stronger protection, cutting ASR by up to 28.8%. These results highlight a crucial gap: defending tool-enabled agents requires reasoning over entire action sequences and their cumulative effects, rather than evaluating isolated prompts or responses.},
}

@article{li2025safetyanalystinterpretabletransparentsteerable,
      title={SafetyAnalyst: Interpretable, transparent, and steerable safety moderation for AI behavior}, 
      author={Jing-Jing Li and Valentina Pyatkin and Max Kleiman-Weiner and Liwei Jiang and Nouha Dziri and Anne G. E. Collins and Jana Schaich Borg and Maarten Sap and Yejin Choi and Sydney Levine},
      abstract={The ideal AI safety moderation system would be both structurally interpretable (so its decisions can be reliably explained) and steerable (to align to safety standards and reflect a community’s values), which current systems fall short on. To address this gap, we present SAFETYANALYST, a novel AI safety moderation framework. Given an AI behavior, SAFETYANALYST uses chainof-thought reasoning to analyze its potential consequences by creating a structured “harm-benefit tree,” which enumerates harmful and beneficial actions and effects the AI behavior may lead to, along with likelihood, severity, and immediacy labels that describe potential impact on any stakeholders. SAFETYANALYST then aggregates all harmful and beneficial effects into a harmfulness score using fully interpretable weight parameters, which can be aligned to particular safety preferences. We applied this conceptual framework to develop, test, and release an opensource LLM prompt safety classification system, distilled from 18.5 million harm-benefit features generated by frontier LLMs on 19k prompts. On a comprehensive set of prompt safety benchmarks, we show that SAFETYANALYST (average F1=0.81) outperforms existing LLM safety moderation systems (average F1<0.72) on prompt safety classification, while offering the additional advantages of interpretability, transparency, and steerability.},
      year={2025},
      journal={ICML},
      url={https://openreview.net/forum?id=WUGrleBcYP}, 
      html={https://jl3676.github.io/SafetyAnalyst},
      pdf={https://openreview.net/pdf?id=WUGrleBcYP},
      code={https://github.com/jl3676/SafetyAnalyst},
      selected={true},
      keywords={Conference, AI Safety, LLM},
      preview={safetyanalyst.jpg}
}

@article{li2024algorithmic,
  title={An algorithmic account for how humans efficiently learn, transfer, and compose hierarchically structured decision policies},
  author={Li, Jing-Jing and Collins, Anne},
  abstract={Learning structures that effectively abstract decision policies is key to the flexibility of human intelligence. Previous work has shown that humans use hierarchically structured policies to efficiently navigate complex and dynamic environments. However, the computational processes that support the learning and construction of such policies remain insufficiently understood. To address this question, we tested 1,026 human participants on a decision-making task where they could learn, transfer, and recompose multiple sets of hierarchical policies. We propose a novel algorithmic account for the learning processes underlying observed human behavior. We show that humans rely on compressed policies over states in early learning, which gradually unfold into hierarchical representations via meta-learning and Bayesian inference. Our modeling evidence suggests that these hierarchical policies are structured in a temporally backward, rather than forward, fashion. Taken together, these algorithmic architectures characterize how the interplay between reinforcement learning, policy compression, meta-learning, and working memory supports structured decision-making and compositionality in a resource-rational way.},
  year={2025},
  volume={254},
  pages={105967},
  publisher={Elsevier},
  journal={Cognition},
  html={https://www.sciencedirect.com/science/article/pii/S0010027724002531},
  pdf={learning_hierarchy.pdf},
  code={https://github.com/jl3676/learning_hierarchy},
  selected={true},
  preview={learning_hierarchy.jpg},
  keywords={Journal, Human Intelligence, Reinforcement Learning, Computational Modeling}
}

@inproceedings{li2025humans,
  title={Humans integrate heuristics and Bayesian inference to efficiently explore under uncertainty},
  author={Li, Jing-Jing and Chen, Connor and Collins, Anne GE},
  booktitle={CogSci},
  year={2025},
  abstract={Exploring the environment efficiently and exploiting learned information effectively are crucial to intelligent agent behavior. Prior work has shown that humans can manage the exploration-exploitation trade-off not only action-by-action, but also at the strategy or rule level, using a heuristic on rule certainty (Collins & Koechlin, 2012). We evaluated this theory on a partially observable rule-switching task and collected human behavioral data (n=112) on two task variants with different levels of rule complexity to test whether taxing cognitive resources impacts exploration heuristics. Our results replicated previous findings, showing that the model is robust to dynamically switching task structure and increased executive demands due to rule complexity. Additionally, we identified a novel meta-heuristic of using high-level rule structure to inform decision-making and computationally characterized its integration with Bayesian inference to support efficient exploration. Through modeling analyses, we show that increased demand on executive function might interfere with this meta-cognitive process.},
  pdf={https://escholarship.org/content/qt2k32x4v7/qt2k32x4v7.pdf},
  keywords={Conference, Human Intelligence, Reinforcement Learning, Computational Modeling},
  preview={heuristic_bayesian.jpg}
}

@article{pan2025latent,
  title={Latent variable sequence identification for cognitive models with neural network estimators},
  author={Pan, Ti-Fen and Li, Jing-Jing and Thompson, Bill and GE Collins, Anne},
  journal={Behavior Research Methods},
  volume={57},
  number={10},
  pages={272},
  year={2025},
  publisher={Springer},
  html={https://link.springer.com/article/10.3758/s13428-025-02794-0},
  abstract={Extracting time-varying latent variables from computational cognitive models plays a key role in uncovering the dynamic cognitive processes that drive behaviors. However, existing methods are limited to inferring latent variable sequences in a relatively narrow class of cognitive models. For example, a broad class of relevant cognitive models with intractable likelihood is currently out of reach of standard techniques, based on maximum a posteriori parameter estimation. Here, we present a simulation-based approach that leverages recurrent neural networks to map experimental data directly to the targeted latent variable space. We first show in simulations that our approach achieves competitive performance in inferring latent variable sequences in both likelihood-tractable and intractable models. We then demonstrate its applicability in real world datasets. Furthermore, the approach is practical to standard-size, individual data, generalizable across different computational models, and adaptable for continuous and discrete latent spaces. Our work underscores that combining recurrent neural networks and simulated data to identify model latent variable sequences broadens the scope of cognitive models researchers can explore, enabling testing a wider range of theories.},
  preview={lasenet.jpg},
  keywords={Journal, Computational Modeling, Method Development}
}

@article{chase2025genetic,
  title={Genetic changes linked to two different syndromic forms of autism enhance reinforcement learning in adolescent male but not female mice},
  author={Chase, Juliana and Li, Jing-Jing and Lin, Wan Chen and Tai, Lung-Hao and Collins, Anne GE and Wilbrecht, Linda},
  journal={bioRxiv},
  pages={2025--01},
  year={2025},
  publisher={Cold Spring Harbor Laboratory},
  html={https://www.biorxiv.org/content/10.1101/2025.01.15.633099v1},
  pdf={https://www.biorxiv.org/content/10.1101/2025.01.15.633099v1.full.pdf},
  abstract={Autism Spectrum Disorder (ASD) is characterized by restricted and repetitive behaviors and social differences, both of which may manifest, in part, from underlying differences in corticostriatal circuits and reinforcement learning. Here, we investigated reinforcement learning in mice with mutations in either Tsc2 or Shank3, both high-confidence ASD risk genes associated with major syndromic forms of ASD. Using an odor-based two-alternative forced choice (2AFC) task, we tested adolescent mice of both sexes and found male Tsc2 and Shank3B heterozygote (Het) mice showed enhanced learning performance compared to their wild type (WT) siblings. No gain of function was observed in females. Using a novel reinforcement learning (RL) based computational model to infer learning rate as well as policy-level task engagement and disengagement, we found that the gain of function in males was driven by an enhanced positive learning rate in both Tsc2 and Shank3B Het mice. The gain of function in Het males was absent when mice were trained with a probabilistic reward schedule. These findings in two ASD mouse models reveal a convergent learning phenotype that shows similar sensitivity to sex and environmental uncertainty. These data can inform our understanding of both strengths and challenges associated with autism, while providing further evidence that sex and experience of uncertainty modulate autism-related phenotypes.},
  keywords={Preprint, Reinforcement Learning, Neuroscience, Computational Modeling},
  preview={asd_mice.jpg}
}

@article{li2024dynamic,
  title={Dynamic noise estimation: A generalized method for modeling noise fluctuations in decision-making},
  author={Li, Jing-Jing and Shi, Chengchun and Li, Lexin and Collins, Anne GE},
  abstract={Computational cognitive modeling is an important tool for understanding the processes supporting human and animal decision-making. Choice data in decision-making tasks are inherently noisy, and separating noise from signal can improve the quality of computational modeling. Common approaches to model decision noise often assume constant levels of noise or exploration throughout learning (e.g., the softmax policy). However, this assumption is not guaranteed to hold – for example, a subject might disengage and lapse into an inattentive phase for a series of trials in the middle of otherwise low-noise performance. Here, we introduce a new, computationally inexpensive method to dynamically estimate the levels of noise fluctuations in choice behavior, under a model assumption that the agent can transition between two discrete latent states (e.g., fully engaged and random). Using simulations, we show that modeling noise levels dynamically instead of statically can substantially improve model fit and parameter estimation, especially in the presence of long periods of noisy behavior, such as prolonged lapses of attention. We further demonstrate the empirical benefits of dynamic noise estimation at the individual and group levels by validating it on four published datasets featuring diverse populations, tasks, and models. Based on the theoretical and empirical evaluation of the method reported in the current work, we expect that dynamic noise estimation will improve modeling in many decision-making paradigms over the static noise estimation method currently used in the modeling literature, while keeping additional model complexity and assumptions minimal.},
  journal={Journal of Mathematical Psychology},
  volume={119},
  pages={102842},
  year={2024},
  publisher={Elsevier},
  html={https://www.sciencedirect.com/science/article/pii/S0022249624000129},
  pdf={dynamic_noise_estimation.pdf},
  code={https://github.com/jl3676/dynamic_noise_estimation},
  selected={true},
  preview={dynamic_noise_estimation.jpg},
  keywords={Journal, Computational Modeling, Method Development}
}

@article{jin2024neural,
  title={Neural mechanisms of awareness of action},
  author={Jin, David S and Agdali, Oumayma and Yadav, Taruna and Kronemer, Sharif I and Kunkler, Sydney and Majumder, Shweta and Khurana, Maya and McCusker, Marie C and Fu, Ivory and Siff, Emily J and Khalaf, Aya and Christison-Lagay, Kate L and Aerts, Shanae L and Xin, Qilong and Li, Jing-Jing and McGill, Sarah H and Crowley, Michael J and Blumenfeld, Hal},
  journal={bioRxiv},
  pages={2024--08},
  year={2024},
  publisher={Cold Spring Harbor Laboratory},
  abstract={The origins of awareness of action (AoA), the ability to report an action just performed, remain elusive. Differing theories ascribe AoA to pre-action, efferent motor/volitional mechanisms versus post-action, afferent sensory/perceptual neural mechanisms. To study these two types of mechanisms and others, we developed a paradigm where very similar aware and unaware actions occur repeatedly. Aware actions demonstrated larger neurophysiological signals both preceding and following movement. The differences included well-known volitional and perceptual event related potentials (PMP, N140, P300), as well as frontal midline theta, event-related alpha/beta desynchronization, and post-move blink rates. On longer time scales, we identified a novel event related potential preceding unaware moves, and found behavioral and pupillometric evidence for decreased attention and arousal over minutes concurrent with AoA loss. Our findings suggest that both dynamic, individual action-associated volitional and perceptual neural activity, as well as long-term attention and arousal states play a role in maintaining AoA.},
  pdf={https://www.biorxiv.org/content/10.1101/2024.08.15.608153v2.full.pdf},
  preview={aoa.jpg},
  keywords={Preprint, Neuroscience}
}

@article{li2023generalized,
  title={A generalized method for dynamic noise inference in modeling sequential decision-making},
  author={Li, Jing-Jing and Shi, Chengchun and Li, Lexin and Collins, Anne GE},
  abstract={Computational cognitive modeling is an important tool for understanding the processes that support human and animal decision-making. Choice data in sequential decision-making tasks are inherently noisy, and separating noise from signal can improve the quality of computational modeling. Currently, most models assume that noise is constant, or static, typically by including a parameter (e.g., uniform ε) to estimate the noise level. However, this assumption is not guaranteed to hold -- for example, an agent can lapse into an inattentive phase for a series of trials in the middle of otherwise low-noise performance. Assuming that noise is static could bias parameter and model identification. Here, we propose a new method to dynamically infer noise in choice behavior, under a model assumption that agents can transition between two discrete latent states (for example, attentive and noisy). Using four empirical datasets with diverse behavioral and modeling features, we demonstrate that our method improves model fit and that it can be easily incorporated into existing fitting procedures, including maximum likelihood estimation and hierarchical Bayesian modeling.},
  journal={CogSci},
  year={2023},
  html={https://escholarship.org/uc/item/7p00v6c5},
  pdf={https://escholarship.org/content/qt7p00v6c5/qt7p00v6c5.pdf},
  preview={dynamic_noise_estimation.jpg},
  keywords={Conference, Computational Modeling, Method Development}
}

@article{mccafferty2023decreased,
  title={Decreased but diverse activity of cortical and thalamic neurons in consciousness-impairing rodent absence seizures},
  author={McCafferty, Cian and Gruenbaum, Benjamin F and Tung, Renee and Li, Jing-Jing and Zheng, Xinyuan and Salvino, Peter and Vincent, Peter and Kratochvil, Zachary and Ryu, Jun Hwan and Khalaf, Aya and Swift, Kohl and Akbari, Rashid and Islam, Wasif and Antwi, Prince and Johnson, Emily A and Vitkovskiy, Petr and Sampognaro, James and Freedman, Isaac G and Kundishora, Adam and Depaulis, Antoine and David, François and Crunelli, Vincenzo and Sanganahalli, Basavaraju G and Herman, Peter and Hyder, Fahmeed and Blumenfeld, Hal},
  journal={Nature Communications},
  volume={14},
  number={1},
  pages={117},
  year={2023},
  html={https://www.nature.com/articles/s41467-022-35535-4},
  publisher={Nature Publishing Group UK London},
  abstract={Absence seizures are brief episodes of impaired consciousness, behavioral arrest, and unresponsiveness, with yet-unknown neuronal mechanisms. Here we report that an awake female rat model recapitulates the behavioral, electroencephalographic, and cortical functional magnetic resonance imaging characteristics of human absence seizures. Neuronally, seizures feature overall decreased but rhythmic firing of neurons in cortex and thalamus. Individual cortical and thalamic neurons express one of four distinct patterns of seizure-associated activity, one of which causes a transient initial peak in overall firing at seizure onset, and another which drives sustained decreases in overall firing. 40–60 s before seizure onset there begins a decline in low frequency electroencephalographic activity, neuronal firing, and behavior, but an increase in higher frequency electroencephalography and rhythmicity of neuronal firing. Our findings demonstrate that prolonged brain state changes precede consciousness-impairing seizures, and that during seizures distinct functional groups of cortical and thalamic neurons produce an overall transient firing increase followed by a sustained firing decrease, and increased rhythmicity.},
  keywords={Journal, Neuroscience},
  preview={gaers.jpg}
}

@article{li2022credit,
  title={Credit assignment in hierarchical option transfer},
  author={Li, Jing-Jing and Xia, Liyu and Dong, Flora and Collins, Anne GE},
  abstract={Humans have the exceptional ability to efficiently structure past knowledge during learning to enable fast generalization. Xia and Collins (2021) evaluated this ability in a hierarchically structured, sequential decision-making task, where participants could build “options” (strategy “chunks”) at multiple levels of temporal and state abstraction. A quantitative model, the Option Model, captured the transfer effects observed in human participants, suggesting that humans create and compose hierarchical options and use them to explore novel contexts. However, it is not well understood how learning in a new context is attributed to new and old options (i.e., the credit assignment problem). In a new context with new contingencies, where participants can recompose some aspects of previously learned options, do they reliably create new options or overwrite existing ones? Does the credit assignment depend on how similar the new option is to an old one? In our experiment, two groups of participants (n=124 and n=104) learned hierarchically structured options, experienced different amounts of negative transfer in a new option context, and were subsequently tested on the previously learned options. Behavioral analysis showed that old options were successfully reused without interference, and new options were appropriately created and credited. This credit assignment did not depend on how similar the new option was to the old option, showing great flexibility and precision in human hierarchical learning. These behavioral results were captured by the Option Model, providing further evidence for option learning and transfer in humans.},
  journal={CogSci},
  year={2022},
  html={https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9751259/},
  pdf={https://escholarship.org/content/qt6pc5s178/qt6pc5s178_noSplash_fadabee184e56ba5cded556553f1fca1.pdf?t=reckne},
  keywords={Conference, Human Intelligence, Computational Modeling, Reinforcement Learning},
  preview={OT-CA.jpg}
}