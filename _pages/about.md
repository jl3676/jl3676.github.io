---
layout: about
title: about
permalink: /
subtitle:

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

## RESEARCH

My research is dedicated to improving the _safety_ of generative AI systems. My goal is to ensure that as AI models become more powerful, they remain robust, interpretable, and aligned with human values. I have applied this focus directly through research internships at [AWS Agentic AI](https://aws.amazon.com/ai/agentic-ai/), where I investigated the adversarial robustness of AI agents, and at the [Allen Institute for AI](https://allenai.org), where I worked on interpretable and transparent safety moderation. Currently, I am a research fellow at [Anthropic](https://www.anthropic.com/research) leading an AI safety research project.

My approach to AI safety is grounded in cognitive science. As a final-year PhD student at UC Berkeley advised by Professor [Anne Collins](https://ccn.studentorg.berkeley.edu/), I investigate the computational principles behind how humans learn, reason, and make decisions. This background provides a unique lens for analyzing complex, human-like behaviors in AI and for constructing high-quality alignment data that reflects nuanced human judgment.
